# Clear workspace
rm(list=ls())
# Load EBImage library
require(EBImage)
install.packages('EBImage')
install.packages("EBImage")
# Clear workspace
rm(list=ls())
# Load data
X <- read.csv("olivetti_X.csv", header = F)
labels <- read.csv("olivetti_y.csv", header = F)
View(X)
View(X)
# Dataframe of resized images
rs_df <- data.frame()
# Load EBImage library
require(EBImage)
install.packages("EBImage")
source("http://bioconductor.org/biocLite.R")
biocLite("EBImage")
write.csv(test_28, "test_28.csv", row.names = FALSE)
# Done!
print("Done!")
# Clear workspace
rm(list=ls())
# Load EBImage library
require(EBImage)
biocLite("EBImage")
source("http://bioconductor.org/biocLite.R")
biocLite("EBImage")
# Reshape as a 64x64 image (EBImage object)
#img <- Image(img, dim=c(64, 64), colormode = "Grayscale")
# Resize image to 28x28 pixels
#img_resized <- resize(img, w = 28, h = 28)
# Get image matrix (there should be another function to do this faster and more neatly!)
img_matrix <- img_resized@.Data    img_matrix <- img_resized@.Data
# Clear workspace
rm(list=ls())
# Load EBImage library
require(EBImage)
# Load data
X <- read.csv("olivetti_X.csv", header = F)
labels <- read.csv("olivetti_y.csv", header = F)
# Dataframe of resized images
rs_df <- data.frame()
# Main loop: for each image, resize and set it to greyscale
for(i in 1:nrow(X))
{
# Try-catch
result <- tryCatch({
# Image (as 1d vector)
img <- as.numeric(X[i,])
# Reshape as a 64x64 image (EBImage object)
#img <- Image(img, dim=c(64, 64), colormode = "Grayscale")
# Resize image to 28x28 pixels
#img_resized <- resize(img, w = 28, h = 28)
# Get image matrix (there should be another function to do this faster and more neatly!)
#img_matrix <- img_resized@.Data
img_matrix <- img@.Data
# Coerce to a vector
img_vector <- as.vector(t(img_matrix))
# Add label
label <- labels[i,]
vec <- c(label, img_vector)
# Stack in rs_df using rbind
rs_df <- rbind(rs_df, vec)
# Print status
print(paste("Done",i,sep = " "))},
# Error function (just prints the error). Btw you should get no errors!
error = function(e){print(e)})
}
# Set names. The first columns are the labels, the other columns are the pixels.
names(rs_df) <- c("label", paste("pixel", c(1:784)))
# Set seed for reproducibility purposes
set.seed(100)
# Shuffled df
shuffled <- rs_df[sample(1:400),]
# Train-test split
train_28 <- shuffled[1:360, ]
test_28 <- shuffled[361:400, ]
# Save train-test datasets
write.csv(train_28, "train_28.csv", row.names = FALSE)
write.csv(test_28, "test_28.csv", row.names = FALSE)
# Done!
print("Done!")
# Clean workspace
rm(list=ls())
# Load MXNet
require(mxnet)
install.packages("mxnet")
install.packages(mxnet)
install.packages("mxnet")
cran <- getOption("repos")
cran["dmlc"] <- "https://s3-us-west-2.amazonaws.com/apache-mxnet/R/CRAN/"
options(repos = cran)
install.packages("mxnet",dependencies = T)
library(mxnet)
library(mxnet)
library(mxnet)
library(mxnet)
library(mxnet)
install.packages("EBImage")
source("http://bioconductor.org/biocLite.R")
biocLite("EBImage")
# Load EBImage library
require(EBImage)
# Load MXNet
require(mxnet)
install.packages("mxnet")
cran <- getOption("repos")
cran["dmlc"] <- "https://s3-us-west-2.amazonaws.com/apache-mxnet/R/CRAN/"
options(repos = cran)
install.packages("mxnet",dependencies = T)
# Load MXNet
require(mxnet)
install.packages("drat", repos="https://cran.rstudio.com")
drat:::addRepo("dmlc")
install.packages("mxnet")
install.packages("rgexf")
install.packages("XML")
install.packages("rgexf")
install.packages("rgexf")
Needed <- c("tm", "SnowballCC", "RColorBrewer", "ggplot2", "wordcloud", "biclust",
"cluster", "igraph", "fpc")
install.packages(Needed, dependencies = TRUE)
install.packages("Rcampdf", repos = "http://datacube.wu.ac.at/", type = "source")
cname <- file.path("~", "Desktop", "msu","IO","lab","lab7","articles")
cname
dir(cname)
install.packages("tm")
install.packages("libxml2-dev")
install.packages("scholar", dependencies=T)
install.packages("ggforce", dependencies=T)
install.packages("units", dependencies=T)
Needed <- c("tm", "SnowballCC", "RColorBrewer", "ggplot2", "wordcloud", "biclust",
"cluster", "igraph", "fpc")
install.packages(Needed, dependencies = TRUE)
install.packages("Rcampdf", repos = "http://datacube.wu.ac.at/", type = "source")
cname <- file.path("~", "mati","IO","articles")
cname
cname <- file.path("home", "mati","IO","articles")
cname
cname <- file.path("~","IO","articles")
cname
dir(cname)
#wymaga libxml2-dev
library(tm)
install.packages("tm")
install.packages("tm")
#wymaga libxml2-dev
library(tm)
docs <- VCorpus(DirSource(cname))
summary(docs)
inspect(docs[1])
docs <- tm_map(docs,removePunctuation)
for (j in seq(docs)) {
docs[[j]] <- gsub("/", " ", docs[[j]])
docs[[j]] <- gsub("@", " ", docs[[j]])
docs[[j]] <- gsub("\\|", " ", docs[[j]])
docs[[j]] <- gsub("\u2028", " ", docs[[j]])
}
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, PlainTextDocument)
DocsCopy <- docs
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, PlainTextDocument)
stopwords("english")
docs[["character(0)"]][["content"]]
#removing words
docs <- tm_map(docs, removeWords, c("s", "l", "h", "th", "-", "—", "–"))
docs <- tm_map(docs, PlainTextDocument)
for (j in seq(docs))
{
docs[[j]] <- gsub("fake news", "fake_news", docs[[j]])
docs[[j]] <- gsub("inner city", "inner-city", docs[[j]])
docs[[j]] <- gsub("politically correct", "politically_correct", docs[[j]])
}
docs <- tm_map(docs, PlainTextDocument)
docs <- tm_map(docs, stripWhitespace)
dtm <- DocumentTermMatrix(docs)
tdm <- TermDocumentMatrix(docs)
freq <- colSums(as.matrix(dtm))
ord <- order(freq)
m <- as.matrix(dtm)
write.csv(m, file="DocumentTermMatrix.csv")
dtms <- removeSparseTerms(dtm, 0.2)
freq <- colSums(as.matrix(dtm))
head(table(freq), 20)
tail(table(freq), 20)
freq <- colSums(as.matrix(dtms))
freq <- sort(colSums(as.matrix(dtm)), decreasing=TRUE)
head(freq, 14)
findFreqTerms(dtm, lowfreq=50)
wf <- data.frame(word=names(freq), freq=freq)
head(wf)
library(ggplot2)
p <- ggplot(subset(wf, freq>50), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat = "identity") +
theme(axis.text.x=element_text(angle=45, hjust=1))
findAssocs(dtm, c("country" , "american"), corlimit=0.85)
findAssocs(dtms, "think", corlimit=0.70)
# install.packages("RColorBrewer")
library(wordcloud)
library(RColorBrewer)
set.seed(142)
wordcloud(names(freq), freq, min.freq=25)
wordcloud(names(freq), freq, max.words=100)
wordcloud(names(freq), freq, min.freq=20, scale=c(5, .1), colors=brewer.pal(6, "Dark2"))
dark2 <- brewer.pal(6, "Dark2")
wordcloud(names(freq), freq, max.words=100, rot.per=0.2, colors=dark2)
dtmss <- removeSparseTerms(dtm, 0.15)
library(cluster)
d <- dist(t(dtmss), method="euclidian")
fit <- hclust(d=d, method="complete")
plot(fit, hang=-1)
plot.new()
plot(fit, hang=-1)
groups <- cutree(fit, k=6)
rect.hclust(fit, k=6, border="red")
library(fpc)
d <- dist(t(dtmss), method="euclidian")
kfit <- kmeans(d, 3)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
library(slam)
cosine_dist_mat <- 1 - crossprod_simple_triplet_matrix(tdm)/(sqrt(col_sums(tdm^2) %*% t(col_sums(tdm^2))))
cname <- file.path("~","IO","articles")
cname
dir(cname)
install.packages("tm")
#wymaga libxml2-dev
library(tm)
docs <- VCorpus(DirSource(cname))
#install.packages("tm")
#wymaga libxml2-dev
library(tm)
docs <- VCorpus(DirSource(cname))
summary(docs)
inspect(docs[1])
docs <- tm_map(docs,removePunctuation)
for (j in seq(docs)) {
docs[[j]] <- gsub("/", " ", docs[[j]])
docs[[j]] <- gsub("@", " ", docs[[j]])
docs[[j]] <- gsub("\\|", " ", docs[[j]])
docs[[j]] <- gsub("\u2028", " ", docs[[j]])
}
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, PlainTextDocument)
DocsCopy <- docs
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, PlainTextDocument)
stopwords("english")
docs[["character(0)"]][["content"]]
#removing words
docs <- tm_map(docs, removeWords, c("s", "l", "h", "th", "-", "—", "–"))
docs <- tm_map(docs, PlainTextDocument)
for (j in seq(docs))
{
docs[[j]] <- gsub("fake news", "fake_news", docs[[j]])
docs[[j]] <- gsub("inner city", "inner-city", docs[[j]])
docs[[j]] <- gsub("politically correct", "politically_correct", docs[[j]])
}
docs <- tm_map(docs, PlainTextDocument)
docs <- tm_map(docs, stripWhitespace)
dtm <- DocumentTermMatrix(docs)
tdm <- TermDocumentMatrix(docs)
freq <- colSums(as.matrix(dtm))
ord <- order(freq)
m <- as.matrix(dtm)
write.csv(m, file="DocumentTermMatrix.csv")
dtms <- removeSparseTerms(dtm, 0.2)
freq <- colSums(as.matrix(dtm))
head(table(freq), 20)
tail(table(freq), 20)
freq <- colSums(as.matrix(dtms))
freq <- sort(colSums(as.matrix(dtm)), decreasing=TRUE)
head(freq, 14)
findFreqTerms(dtm, lowfreq=50)
wf <- data.frame(word=names(freq), freq=freq)
head(wf)
library(ggplot2)
p <- ggplot(subset(wf, freq>50), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat = "identity") +
theme(axis.text.x=element_text(angle=45, hjust=1))
findAssocs(dtm, c("country" , "american"), corlimit=0.85)
findAssocs(dtms, "think", corlimit=0.70)
# install.packages("RColorBrewer")
library(wordcloud)
library(RColorBrewer)
set.seed(142)
wordcloud(names(freq), freq, min.freq=25)
wordcloud(names(freq), freq, max.words=100)
wordcloud(names(freq), freq, min.freq=20, scale=c(5, .1), colors=brewer.pal(6, "Dark2"))
dark2 <- brewer.pal(6, "Dark2")
wordcloud(names(freq), freq, max.words=100, rot.per=0.2, colors=dark2)
dtmss <- removeSparseTerms(dtm, 0.15)
library(cluster)
d <- dist(t(dtmss), method="euclidian")
fit <- hclust(d=d, method="complete")
plot(fit, hang=-1)
plot.new()
plot(fit, hang=-1)
groups <- cutree(fit, k=6)
rect.hclust(fit, k=6, border="red")
library(fpc)
d <- dist(t(dtmss), method="euclidian")
kfit <- kmeans(d, 3)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
library(slam)
cosine_dist_mat <- 1 - crossprod_simple_triplet_matrix(tdm)/(sqrt(col_sums(tdm^2) %*% t(col_sums(tdm^2))))
write.csv(m, file="DocumentTermMatrix.csv")
dtms
head(wf)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
library(slam)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
cosine_dist_mat <- 1 - crossprod_simple_triplet_matrix(tdm)/(sqrt(col_sums(tdm^2) %*% t(col_sums(tdm^2))))
cosine_dist_mat
dtmss
dtm
